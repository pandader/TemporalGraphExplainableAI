{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load title name entity tags and short hand token\n",
    "IMPROT_FILE = 'validData_Reduced.csv'\n",
    "ETET_GRAPHS = 'TemporalGraphData\\ETETGraphs'\n",
    "STANDARD_TITLE_FILES = ['tech_jobs.csv', 'non_tech_jobs.csv']\n",
    "IMPORT_PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Deal with Titles\n",
    "with open(os.path.join(IMPORT_PATH, \"title_id_dict.json\"), \"r\") as openfile:\n",
    "    org_title_2_new_id = json.load(openfile)\n",
    "with open(os.path.join(IMPORT_PATH, \"employee_id_dict.json\"), \"r\") as openfile:\n",
    "    org_employee_id_2_new_id = json.load(openfile)\n",
    "# load standard titles\n",
    "df_titles = pd.concat([pd.read_csv(os.path.join(IMPORT_PATH, STANDARD_TITLE_FILES[0])),  pd.read_csv(os.path.join(IMPORT_PATH, STANDARD_TITLE_FILES[1]))]).drop(columns=['Edu'])\n",
    "df_titles.GROUP = df_titles.GROUP.str.lower(); df_titles.TITLE = df_titles.TITLE.str.lower()\n",
    "# save mapping\n",
    "org_title_gp_2_new_id = {each : 'G' + str(idx) for idx, each in enumerate(df_titles.GROUP.unique())}\n",
    "df_titles['GroupID'] = df_titles.GROUP.apply(lambda x: org_title_gp_2_new_id[x])\n",
    "df_titles['TitleID'] = df_titles.TITLE.apply(lambda x: org_title_2_new_id[x] if x in org_title_2_new_id else np.nan)\n",
    "df_titles.dropna(subset=['TitleID'], inplace=True)\n",
    "with open(os.path.join(IMPORT_PATH, \"title_gp_id_dict.json\"), \"w\") as outFile:\n",
    "    json.dump(org_title_gp_2_new_id, outFile)\n",
    "df_title_hierachy = df_titles[['GroupID', 'TitleID']]\n",
    "### import title embedding matrix\n",
    "z_raw = np.load(os.path.join(IMPORT_PATH, 'title_emb_matrix.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Firm</th>\n",
       "      <th>Title</th>\n",
       "      <th>Start_Date</th>\n",
       "      <th>End_Date</th>\n",
       "      <th>Title_Group</th>\n",
       "      <th>EDU</th>\n",
       "      <th>Duration</th>\n",
       "      <th>DiversityScore</th>\n",
       "      <th>YrsOfExp</th>\n",
       "      <th>Start_Year</th>\n",
       "      <th>End_Year</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>TitleID</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>Job_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACwAAA--S20BZncfI96Y51rtML5hkDoodwbFi-c,NAME_S...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>software developer</td>\n",
       "      <td>computer science, computer engineering, electr...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2021</td>\n",
       "      <td>E1</td>\n",
       "      <td>T1</td>\n",
       "      <td>G0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACwAAA--zVABrailb54YsBsNL_ulhYNRVeX599Y,NAME_S...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>software developer</td>\n",
       "      <td>computer science, computer engineering, electr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "      <td>E2</td>\n",
       "      <td>T1</td>\n",
       "      <td>G0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACwAAA--zVABrailb54YsBsNL_ulhYNRVeX599Y,NAME_S...</td>\n",
       "      <td>JT4</td>\n",
       "      <td>technical analyst</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>it specialist</td>\n",
       "      <td>information technology</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>E2</td>\n",
       "      <td>T2</td>\n",
       "      <td>G8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID    Firm  \\\n",
       "0  ACwAAA--S20BZncfI96Y51rtML5hkDoodwbFi-c,NAME_S...  Amazon   \n",
       "1  ACwAAA--zVABrailb54YsBsNL_ulhYNRVeX599Y,NAME_S...  Amazon   \n",
       "2  ACwAAA--zVABrailb54YsBsNL_ulhYNRVeX599Y,NAME_S...     JT4   \n",
       "\n",
       "               Title  Start_Date    End_Date         Title_Group  \\\n",
       "0  software engineer  2019-12-01  2021-10-01  software developer   \n",
       "1  software engineer  2018-03-01  2019-03-01  software developer   \n",
       "2  technical analyst  2020-01-01  2020-07-01       it specialist   \n",
       "\n",
       "                                                 EDU  Duration  \\\n",
       "0  computer science, computer engineering, electr...         2   \n",
       "1  computer science, computer engineering, electr...         1   \n",
       "2                             information technology         1   \n",
       "\n",
       "   DiversityScore  YrsOfExp  Start_Year  End_Year EmployeeID TitleID GroupID  \\\n",
       "0        0.000000       1.0        2019      2021         E1      T1      G0   \n",
       "1        0.000000       0.0        2018      2019         E2      T1      G0   \n",
       "2        0.693147       1.0        2020      2020         E2      T2      G8   \n",
       "\n",
       "   Job_Index  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import golden source (no duplicates)\n",
    "df = pd.read_csv(os.path.join(IMPORT_PATH, IMPROT_FILE))\n",
    "df['Start_Year'] = df['Start_Date'].apply(lambda x: int(x.split('-')[0]))\n",
    "df['End_Year'] = df['End_Date'].apply(lambda x: int(x.split('-')[0]))\n",
    "df.drop_duplicates(subset=['ID', 'End_Year'], keep='last', inplace=True)\n",
    "df.drop_duplicates(subset=['ID', 'Start_Year'], keep='last', inplace=True)\n",
    "df['EmployeeID'] = df.ID.apply(lambda x: org_employee_id_2_new_id[x])\n",
    "df['TitleID'] = df.Title.apply(lambda x: org_title_2_new_id[x])\n",
    "df['GroupID'] = df.Title_Group.apply(lambda x: org_title_gp_2_new_id[x])\n",
    "df['Job_Index'] = df.groupby('EmployeeID').cumcount()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19377 employees that have experience between 3~10.\n"
     ]
    }
   ],
   "source": [
    "### number of experiences distribution\n",
    "df_count = df.groupby('ID')[['Firm']].count().reset_index().rename(columns={'Firm' : 'Count'})\n",
    "# display(df_count.Count.describe())\n",
    "### sample data ( lb < num exps < ub)\n",
    "lb, ub = 3, 10\n",
    "v = df_count[(df_count.Count >= lb)&(df_count.Count <= ub)]\n",
    "print(f'There are {len(v)} employees that have experience between {lb}~{ub}.')\n",
    "df_sampled = df[df.ID.isin(set(v.ID))].reset_index(drop=True)\n",
    "unique_gps = df_sampled.Title_Group.unique()\n",
    "unique_titles = df_sampled.Title.unique()\n",
    "df_sampled = df_sampled[\n",
    "    ['EmployeeID', 'TitleID', 'GroupID', 'Start_Year', 'End_Year', 'Duration', 'DiversityScore', 'Job_Index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ETET network\n",
    "tmp_col = []\n",
    "path = os.path.join(IMPORT_PATH, ETET_GRAPHS)\n",
    "for yr in range(2008, 2023):\n",
    "    df_tmp = pd.read_csv(os.path.join(path, 'graph_etet_{yr}.csv'.format(yr=yr)))\n",
    "    df_tmp['Year'] = yr\n",
    "    tmp_col.append(df_tmp)\n",
    "df_etet = pd.concat(tmp_col, axis=0)[['Year', 'Focal', 'Reference', 'Start_Year', 'Job_Index', 'TargetTitle']]\n",
    "# path = os.path.join(IMPORT_PATH, ETET_GRAPHS)\n",
    "# df_etet.to_csv(os.path.join(path, 'AggregatedETET.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Data Point:\n",
    "- X:\n",
    "    - EmployeeID    \n",
    "    - Num of Exp\n",
    "    - End_Year\n",
    "    - Job_Index\n",
    "    - Duration\n",
    "    - Diversity Score\n",
    "    - Title Embedding    \n",
    "Format:\n",
    "    1 : [EmployeeID, NumExp, End_Year, Dur, Div, titleEmb]\n",
    "    2 : [EmployeeID, NumExp, End_Year, Dur, Div, titleEmb]\n",
    "    ... \n",
    "    if not as many as upper bound, pad zeros\n",
    "- Y:\n",
    "    - TitleID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeID         E10\n",
       "TitleID            T11\n",
       "GroupID            G30\n",
       "Start_Year        2008\n",
       "End_Year          2008\n",
       "Duration             1\n",
       "DiversityScore     0.0\n",
       "Job_Index            0\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n"
     ]
    }
   ],
   "source": [
    "### we shall pad a full seq starting from 2008 -> 2022\n",
    "count = 0\n",
    "x, y = [], []\n",
    "gps = df_sampled.groupby('EmployeeID')\n",
    "for id, profile in gps:\n",
    "    # below two attributes are shared across one profile\n",
    "    employee_id = int(id.split('E')[1]) # employee id\n",
    "    num_exp = len(profile) # career length\n",
    "    x_col, y_col = [], []\n",
    "    job_count = 0\n",
    "    for _, row in profile.iterrows():\n",
    "        dur = row.Duration # duration\n",
    "        end_yr = row.End_Year # end year\n",
    "        job_idx = row.Job_Index\n",
    "        title_id = int(row.TitleID.split('T')[1])-1 # title id\n",
    "        t_emb = z_raw[title_id] # title embedding\n",
    "        div = row.DiversityScore # diversity score\n",
    "        x_col.append([employee_id, num_exp, end_yr, job_idx, dur, div] + t_emb.tolist())\n",
    "        y_col.append([title_id])\n",
    "    # x for one profile\n",
    "    x_stack = np.stack(x_col)\n",
    "    x.append(np.concatenate([x_stack, np.zeros(((ub - num_exp), len(x_col[0])))], axis=0))\n",
    "    # y for one profile\n",
    "    y_stack = np.stack(y_col)\n",
    "    y.append(np.concatenate([y_stack, np.zeros(((ub - num_exp), len(y_col[0])))], axis=0))\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "# turn np to tensor\n",
    "x_tensor = torch.FloatTensor(x)\n",
    "y_tensor = torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split\n",
    "num_samples = len(x_tensor)\n",
    "test_samples = round(0.1 * num_samples)\n",
    "test_idx = np.random.choice(list(range(num_samples)), test_samples)\n",
    "x_test_tensor = x_tensor[test_idx]\n",
    "y_test_tensor = y_tensor[test_idx]\n",
    "train_idx = list(set(range(num_samples)) - set(test_idx))\n",
    "x_train_tensor = x_tensor[train_idx]\n",
    "y_train_tensor = y_tensor[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save data set\n",
    "export_path = os.path.join(IMPORT_PATH, 'TemporalGraphData\\TrainTestData')\n",
    "torch.save(x_train_tensor, os.path.join(export_path, 'TRAIN_X.pt'))\n",
    "torch.save(y_train_tensor, os.path.join(export_path, 'TRAIN_Y.pt'))\n",
    "torch.save(x_test_tensor, os.path.join(export_path, 'TEST_X.pt'))\n",
    "torch.save(y_test_tensor, os.path.join(export_path, 'TEST_Y.pt'))\n",
    "# debug data set\n",
    "torch.save(x_train_tensor[:100], os.path.join(export_path, 'DEBUG_X.pt'))\n",
    "torch.save(y_train_tensor[:100], os.path.join(export_path, 'DEBUG_Y.pt'))\n",
    "torch.save(x_test_tensor[:100], os.path.join(export_path, 'DEBUG_TEST_X.pt'))\n",
    "torch.save(y_test_tensor[:100], os.path.join(export_path, 'DEBUG_TEST_Y.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data loader\n",
    "class CustomDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, root_path, x_file, y_file, title_emb_dim=384, use_cuda=False):\n",
    "        self.dataset = torch.load(os.path.join(root_path, x_file),)\n",
    "        self.labels = torch.load(os.path.join(root_path, y_file))\n",
    "        self.title_emb_dim = title_emb_dim\n",
    "        if use_cuda:\n",
    "            self.dataset = self.dataset.cuda()\n",
    "            self.labels = self.labels.cuda()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ### Reminder\n",
    "        # Create Data Point:\n",
    "        # - X:\n",
    "        #     - EmployeeID    \n",
    "        #     - Num of Exp\n",
    "        #     - End_Year\n",
    "        #     - Job_Index\n",
    "        #     - Duration\n",
    "        #     - Diversity Score\n",
    "        #     - Title Embedding\n",
    "\n",
    "        # Format:\n",
    "        #     1 : [EmployeeID, NumExp, End_Year, Dur, Div, titleEmb]\n",
    "        #     2 : [EmployeeID, NumExp, End_Year, Dur, Div, titleEmb]\n",
    "        #     ... \n",
    "        #     if not as many as upper bound, pad zeros\n",
    "        # - Y:\n",
    "        #     - TitleID\n",
    "        x, y = self.dataset[idx], self.labels[idx]\n",
    "        emp_id = x[:, 0]\n",
    "        num_exp = x[:, 1:2]\n",
    "        end_yr = x[:, 2:3]\n",
    "        job_idx = x[:, 3:4]\n",
    "        dur = x[:, 4:5]\n",
    "        div = x[:, 5:6]\n",
    "        t_emb = x[:, 6:]\n",
    "        return emp_id[0], num_exp[0], end_yr, job_idx, dur, div, t_emb, y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "import_path = os.path.join(IMPORT_PATH, 'TemporalGraphData\\TrainTestData')\n",
    "title_emb_dim = z_raw.shape[1]\n",
    "train_dataset = CustomDataSet(import_path, 'TRAIN_X.pt', 'TRAIN_Y.pt', title_emb_dim)\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (emp_id, num_exp, end_yr, job_index, dur, div, t_emb, label) in enumerate(train_dataloader):\n",
    "    break\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
